# Datadog Synthetic Events

A tool for simulating and sending synthetic events to Datadog via both API and email for testing and demonstration purposes.

## Overview

This project allows you to:
1. Generate synthetic monitoring events from predefined scenarios
2. Send events to Datadog via direct API calls
3. Send events via email to be parsed by Datadog's email integration
4. Simulate different alert patterns and test Datadog's processing capabilities

## Prerequisites

- Python 3.8+
- Datadog API and APP keys
- SendGrid API key (for email functionality)
- Docker (optional, for containerized execution)

## Installation

### Local Setup

1. Clone the repository:
   ```
   git clone https://github.com/yourusername/datadog-synthetic-events.git
   cd datadog-synthetic-events
   ```

2. Create a virtual environment and install dependencies:
   ```
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. Set up environment variables:
   ```
   export DD_API_KEY="your_datadog_api_key"
   export DD_APP_KEY="your_datadog_app_key"
   export SENDGRID_API_KEY="your_sendgrid_api_key"
   export EMAIL_TO="destination_email@example.com"
   export EMAIL_FROM="source_email@example.com"
   ```

   Alternatively, copy the `set_datadog_env.sh` template and fill in your keys:
   ```
   cp set_datadog_env.sh.template set_datadog_env.sh
   # Edit set_datadog_env.sh with your keys
   source set_datadog_env.sh
   ```

### Docker Setup

1. Build the Docker image:
   ```
   docker build -t datadog-synthetic-events .
   ```

2. Run the container with environment variables:
   ```
   docker run -e DD_API_KEY="your_datadog_api_key" \
              -e DD_APP_KEY="your_datadog_app_key" \
              -e SENDGRID_API_KEY="your_sendgrid_api_key" \
              -e EMAIL_TO="destination_email@example.com" \
              -e EMAIL_FROM="source_email@example.com" \
              datadog-synthetic-events
   ```

## Usage

### Running the Simulator

Use the `run.sh` script to execute the simulator:

```
./run.sh [scenario_name] [--api-only] [--email-only]
```

- `scenario_name`: Name of the scenario folder in `examples/scenarios/` (defaults to "scenario1" if not specified)
- `--api-only`: Only send events via the Datadog API
- `--email-only`: Only send events via email

Example:
```
./run.sh scenario2 --email-only
```

### Creating Custom Scenarios

Scenarios are defined in the `examples/scenarios/` directory. Each scenario should contain:

1. `api_events.json` - Events to be sent directly via Datadog API
2. `email_events.json` - Event templates for email sending
3. `email_logs.json` - Simulated log events to be sent via email

Example scenario file structure:
```
examples/scenarios/my_scenario/
  ├── api_events.json
  ├── email_events.json
  └── email_logs.json
```

#### API Events Format

```json
{
  "events": [
    {
      "title": "Event title",
      "text": "Event description and details",
      "alert_type": "error|warning|info|success",
      "source_type_name": "my_apps",
      "tags": ["key1:value1", "key2:value2"]
    }
  ]
}
```

#### Email Events Format

```json
{
  "events": [
    {
      "subject": "Email subject line",
      "body": "Email body text with alert details",
      "tags": ["key1:value1", "key2:value2"]
    }
  ]
}
```

#### Email Logs Format

```json
{
  "events": [
    {
      "source": "source_name",
      "service": "service_name",
      "hostname": "host_name",
      "tags": ["key1:value1", "key2:value2"],
      "content": "Log content with structured alert information"
    }
  ]
}
```

## Datadog Configuration

To effectively use the synthetic events generated by this tool, proper configuration within your Datadog environment is crucial. This involves setting up email integration, event processing pipelines, and event correlation.

### Email Integration Setup

1.  In Datadog, navigate to  **Organization Settings** > **Events API emails** to create inbound emails for event submission via email
2.  Set this email address as the `EMAIL_TO` environment variable for this tool.

Refer to the official Datadog documentation for the most current steps on [setting up email-to-event processing](https://docs.datadoghq.com/service_management/events/guides/email/).

### Event Processing Pipeline Configuration

Datadog Event Management Pipelines allow you to process, enrich, and normalize incoming events. For the email events sent by this tool, you'll need to configure a pipeline to parse them correctly.

1.  Navigate to **Logs** > **Pipelines** (or **Event Management** > **Pipelines**, depending on your Datadog UI version and features enabled).
2.  Create a new pipeline or modify an existing one. Apply a filter to this pipeline to target emails sent by this tool (e.g., `source:email` or a tag you've configured in the Events API email setup).
3.  Within this pipeline, add the following processors:

    #### a. Grok Parser for Email Body
    This processor will parse the structured information from the body of the emails generated by the tool.

    -   **Processor Type**: Grok Parser
    -   **Rule**:
        ```grok
        rule_name .*Alert Title:\s*%{data:alert_title}\s*Alert Description:\s*%{data:alert_description}\s*Alert Type:\s*%{data:alert_type}\s*Severity:\s*%{data:severity}\s*Alert Level:\s*%{data:alert_level}\s*Device:\s*%{data:device}\s*Time Detected:\s*%{data:time_detected}\s*Notification Time:\s*%{data:notification_time}\s*Notification Policy:\s*%{data:notification_policy}\s*Action Name:\s*%{data:action_name}\s*User URL:\s*%{data:user_url}\s*Location:\s*%{data:location}\s*Primary Contact:\s*%{data:primary_contact}\s*Notes:\s*%{data:notes}\s*Alert ID:\s*%{data:alert_id}\s*Version:\s*%{data:version}
        ```
        *Note: Replace `rule_name` with a descriptive name for your parsing rule.*
    -   **Purpose**: This rule extracts key fields from the email body into structured attributes on your Datadog events. These attributes (e.g., `alert_title`, `alert_id`, `location`) are then available for searching, faceting, and correlation.

    #### b. Lookup Processor for IP to Location Mapping (Optional but Recommended)
    If your event data includes device IP addresses and you want to derive a location, a Lookup Processor can map these IPs to human-readable location names.

    -   **Processor Type**: Lookup Processor
    -   **Configuration**: Configure this processor to take an IP address attribute (e.g., from `device` if it contains an IP, or another relevant attribute) and map it to a new or existing location attribute using a mapping table or GeoIP lookup capabilities if available within the processor.
    -   **Purpose**: Enriches events with standardized location information, which is valuable for correlation and geographical analysis of alerts.

    #### c. Category Processor for Location Normalization
    To ensure consistent location data for effective correlation, especially if location information comes from various fields or has slight variations.

    -   **Processor Type**: Category Processor
    -   **Configuration**: Configure this processor to match different representations of the same location (e.g., "New York", "NYC", "new_york_office") and normalize them to a standard value (e.g., "New York"). Target the `location` attribute (or the attribute populated by the Lookup Processor).
    -   **Purpose**: Standardizes the `location` attribute, which is crucial for accurate event correlation based on location.

For more details on pipeline configuration, refer to the [Datadog Event Management Pipelines documentation](https://docs.datadoghq.com/service_management/events/pipelines_and_processors/).

### Event Correlation Configuration

Event correlation helps group related alerts from different sources (e.g., API and email) or related to the same underlying issue, reducing alert noise and aiding in incident management.

1.  Navigate to **Logs** > **Correlations** (or **Event Management** > **Correlations**).
2.  Create a new correlation definition.
3.  Define correlation criteria using the attributes extracted and normalized by your pipeline. A common strategy includes:
    -   **Primary Identifier**: `alert_id` (if this ID is unique to an incident and can appear in multiple related events).
    -   **Supporting Attributes**: Consider correlating events that share the same `alert_title`, `severity`, and normalized `location`.
    -   **Time Window**: Define an appropriate time window for events to be considered for correlation.
4.  **Purpose**: This configuration will automatically group related events in the Events Explorer, providing a more consolidated view of incidents.

Refer to Datadog's documentation on [Event Correlation](https://docs.datadoghq.com/service_management/events/correlation/) for detailed guidance.

## Troubleshooting

- **Events not appearing in Datadog**: Verify your API keys and check that your network allows connections to Datadog's endpoints.
- **Email not being processed**: Confirm your SendGrid API key is valid and that the destination email is correctly configured in Datadog's email integration.
- **Pipeline not parsing emails**: Review the Grok rule syntax and test it in Datadog's Pipeline testing tool with a sample of your email content.

## License

MIT License

Copyright (c) [year] [fullname]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

## Contributing

[Your Contribution Information]